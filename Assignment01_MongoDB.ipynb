{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**THEORETICAL QUESTIONS**"
      ],
      "metadata": {
        "id": "HQoJSfsC75dI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What are the key differences between SQL and NoSQL databases?**\n",
        "\n",
        "Ans:\n",
        "SQL and NoSQL databases have distinct approaches to storing and managing data. Here are the key differences:\n",
        "Schema: SQL databases use a fixed schema, whereas NoSQL databases have dynamic or flexible schemas.\n",
        "Data Structure: SQL databases use tables, whereas NoSQL databases use documents, key-value pairs, graphs, or wide-column stores.\n",
        "Scalability: SQL databases scale vertically, whereas NoSQL databases scale horizontally.\n",
        "Data Relationships: SQL databases are better suited for complex relationships, whereas NoSQL databases are better for simple or no relationships.\n",
        "ACID Compliance: SQL databases follow ACID principles, whereas NoSQL databases often sacrifice some ACID properties for higher performance and scalability.\n",
        "Query Language: SQL databases use Structured Query Language (SQL), whereas NoSQL databases use query languages specific to their data model."
      ],
      "metadata": {
        "id": "q6CE4TAc8Cka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  What makes MongoDB a good choice for modern applications?**\n",
        "\n",
        "Ans:\n",
        "MongoDB is a popular NoSQL database that offers several benefits for modern applications. Here are some reasons why MongoDB is a good choice:\n",
        "Flexible Schema: MongoDB's dynamic schema allows for easy adaptation to changing data structures, reducing the need for costly schema migrations.\n",
        "Scalability: MongoDB scales horizontally, making it suitable for high-traffic applications and large datasets.\n",
        "High Performance: MongoDB's document-based data model and indexing capabilities enable fast query performance.\n",
        "Easy Data Integration: MongoDB supports various data formats, including JSON, making it easy to integrate with modern web and mobile applications.\n",
        "Real-time Data Processing: MongoDB's support for real-time data processing and analytics enables applications to respond quickly to changing data.\n",
        "Cloud-Native: MongoDB is designed for cloud environments, offering flexible deployment options and seamless scalability.\n",
        "Large Community: MongoDB has a large and active community, ensuring there, are many resources available for learning and troubleshooting."
      ],
      "metadata": {
        "id": "so4LPivW998H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Explain the concept of collections in MongoDB.**\n",
        "\n",
        "Ans:\n",
        "In MongoDB, a collection is a group of documents that are stored together in a database. Collections are similar to tables in relational databases, but they don't enforce a fixed schema. Here's how collections work:\n",
        "Document grouping: Collections store documents that share a common purpose or theme.\n",
        "Schema flexibility: Each document in a collection can have a different structure, allowing for flexible data modeling.\n",
        "No strict schema: Unlike relational databases, MongoDB collections don't enforce a strict schema, giving you more freedom to adapt to changing data structures.\n",
        "Indexing and querying: You can create indexes on collections to improve query performance and use MongoDB's query language to retrieve specific documents."
      ],
      "metadata": {
        "id": "iaGpstCb-Vsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.  How does MongoDB ensure high availability using replication?**\n",
        "\n",
        "Ans:\n",
        "MongoDB ensures high availability using replication, which involves maintaining multiple copies of data across different nodes. Here's how it works:\n",
        "Replica Set: A replica set is a group of MongoDB nodes that maintain the same data set. One node is designated as the primary node, and the others are secondary nodes.\n",
        "Primary Node: The primary node accepts write operations and replicates the data to secondary nodes.\n",
        "Secondary Nodes: Secondary nodes replicate the data from the primary node and can become the new primary if the current primary fails.\n",
        "Automatic Failover: If the primary node fails, the replica set automatically elects a new primary node, ensuring minimal downtime.\n",
        "Data Redundancy: Replication provides data redundancy, which helps protect against data loss due to hardware failure or other issues."
      ],
      "metadata": {
        "id": "5rHo-l8S-ow6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What are the main benefits of MongoDB Atlas **\n",
        "\n",
        "Ans:\n",
        "MongoDB Atlas is a cloud-based MongoDB service that offers several benefits, including:\n",
        "Managed Service: Atlas handles database management tasks, such as provisioning, patching, and scaling, freeing up your team to focus on application development.\n",
        "Scalability: Atlas allows you to easily scale your database up or down to match changing application demands.\n",
        "High Availability: Atlas provides built-in replication and automatic failover, ensuring high availability and data protection.\n",
        "Security: Atlas offers advanced security features, such as encryption at rest and in transit, network access controls, and identity and access management.\n",
        "Monitoring and Alerts: Atlas provides real-time monitoring and alerting, helping you identify and resolve issues quickly.\n",
        "Global Clusters: Atlas supports global clusters, enabling you to distribute data across multiple regions and improve application performance.\n",
        "Integration with MongoDB Tools: Atlas integrates seamlessly with MongoDB's suite of tools, including Compass, Stitch, and Charts.\n",
        "Cost-Effective: Atlas offers a pay-as-you-go pricing model, allowing you to only pay for the resources you use."
      ],
      "metadata": {
        "id": "aBHqGh9y_GTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the role of indexes in MongoDB, and how do they improve performance?**\n",
        "\n",
        "Ans:\n",
        "In MongoDB, indexes play a crucial role in improving query performance. Here's how:\n",
        "Faster Query Execution: Indexes allow MongoDB to quickly locate specific data, reducing the time it takes to execute queries.\n",
        "Reduced Data Scanning: By using an index, MongoDB can avoid scanning entire collections, which can be time-consuming and resource-intensive.\n",
        "Improved Query Optimization: Indexes help MongoDB's query optimizer choose the most efficient query plan, leading to better performance."
      ],
      "metadata": {
        "id": "ylB5pjdP_dzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.  Describe the stages of the MongoDB aggregation pipeline.**\n",
        "\n",
        "Ans:\n",
        "The MongoDB aggregation pipeline is a powerful framework for data processing and analysis. Here are the main stages:\n",
        "\n",
        "$match: Filters documents based on specified conditions.\n",
        "$project: Reshapes documents, including adding, removing, or renaming fields.\n",
        "\n",
        "$group: Groups documents by specified fields and applies aggregation operators (e.g., $sum, $avg).\n",
        "\n",
        "$sort: Sorts documents in ascending or descending order.\n",
        "$limit: Limits the number of documents returned.\n",
        "\n",
        "$skip: Skips a specified number of documents.\n",
        "$unwind: Deconstructs array fields into separate documents.\n",
        "\n",
        "$lookup: Performs left outer join with another collection.\n",
        "$addFields: Adds new fields to documents.\n",
        "\n",
        "$bucket: Groups documents into buckets based on specified boundaries."
      ],
      "metadata": {
        "id": "yME5u07N_wpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.  What is sharding in MongoDB? How does it differ from replication?**\n",
        "\n",
        "Ans:\n",
        "In MongoDB, sharding is a technique for distributing data across multiple servers or nodes to improve scalability and performance. Here's how it works:\n",
        "Horizontal partitioning: Sharding involves dividing data into smaller chunks, called shards, and distributing them across multiple nodes.\n",
        "Shard key: A shard key is used to determine which shard a document belongs to.\n",
        "Scalability: Sharding allows MongoDB to scale horizontally, handling large amounts of data and high traffic.\n",
        "Sharding differs from replication in several ways:\n",
        "Purpose: Replication is used for high availability and data protection, while sharding is used for scalability and performance.\n",
        "Data distribution: Replication duplicates data across nodes, while sharding distributes data across nodes.\n",
        "Node roles: In replication, nodes can be primary or secondary, while in sharding, nodes are shards that store a portion of the data."
      ],
      "metadata": {
        "id": "On8HpxKIAewF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is PyMongo, and why is it used?**\n",
        "\n",
        "Ans:\n",
        "PyMongo is a Python distribution containing tools for working with MongoDB. It's a popular driver that allows Python developers to interact with MongoDB databases.\n",
        "PyMongo is used for:\n",
        "Connecting to MongoDB: PyMongo provides a way to connect to MongoDB instances, including replica sets and sharded clusters.\n",
        "Performing CRUD operations: PyMongo allows you to create, read, update, and delete documents in MongoDB collections.\n",
        "Querying data: PyMongo supports various query methods, including filtering, sorting, and aggregating data.\n",
        "Working with MongoDB features: PyMongo provides access to MongoDB features like GridFS, MapReduce, and aggregation framework."
      ],
      "metadata": {
        "id": "zT_Ssz1hA2Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What are the ACID properties in the context of MongoDB transactions?**\n",
        "\n",
        "Ans:\n",
        "In the context of MongoDB transactions, ACID properties refer to a set of guarantees that ensure database transactions are processed reliably. ACID stands for:\n",
        "Atomicity: Ensures that transactions are treated as a single, indivisible unit. If any part of the transaction fails, the entire transaction is rolled back.\n",
        "Consistency: Ensures that the database remains in a consistent state, even after multiple transactions have been applied.\n",
        "Isolation: Ensures that transactions are executed independently, without interference from other transactions.\n",
        "Durability: Ensures that once a transaction is committed, its effects are permanent and survive even in the event of a failure."
      ],
      "metadata": {
        "id": "6U-Qni6pBHz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. What is the purpose of MongoDB’s explain() function?**\n",
        "\n",
        "Ans:\n",
        "The explain() function in MongoDB is used to:\n",
        "Analyze query performance: explain() provides detailed information about how MongoDB executes a query, including the query plan, index usage, and execution statistics.\n",
        "Optimize queries: By analyzing the output of explain(), you can identify performance bottlenecks and optimize your queries for better performance.\n",
        "Understand index usage: explain() shows whether MongoDB is using an index to fulfill a query, and if so, which index is being used."
      ],
      "metadata": {
        "id": "TXsaBDoSBSo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.  How does MongoDB handle schema validation?**\n",
        "\n",
        "Ans;\n",
        "MongoDB provides schema validation, which allows you to enforce structure and rules on your data. Here's how it works:\n",
        "JSON Schema: MongoDB uses JSON Schema to define validation rules for documents in a collection.\n",
        "Validation rules: You can specify rules for fields, such as data type, format, and allowed values.\n",
        "Validation levels: MongoDB provides different validation levels, including:\n",
        "Off: No validation is performed.\n",
        "Strict: Validation is enforced for all documents.\n",
        "Moderate: Validation is enforced for inserts and updates, but existing documents are not validated.\n",
        "Validation actions: You can specify actions to take when validation fails, such as:\n",
        "Error: Reject the operation and return an error.\n",
        "Warn: Log a warning message, but allow the operation to proceed."
      ],
      "metadata": {
        "id": "CU2dXHzDBldS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.  What is the difference between a primary and a secondary node in a replica set?**\n",
        "\n",
        "Ans:\n",
        "In a MongoDB replica set:\n",
        "Primary node: The primary node is the main node that accepts write operations. All writes are directed to the primary node, and it is responsible for replicating the data to secondary nodes.\n",
        "Secondary node: Secondary nodes replicate the data from the primary node and can serve read traffic. They can become the new primary node if the current primary fails.\n",
        "Key differences:\n",
        "Write operations: Only the primary node accepts write operations. Secondary nodes replicate the data from the primary node.\n",
        "Read operations: Both primary and secondary nodes can serve read traffic, but secondary nodes may lag behind the primary node due to replication delay.\n",
        "Failover: If the primary node fails, a secondary node can be elected as the new primary node, ensuring high availability."
      ],
      "metadata": {
        "id": "G7jjZT1RB2Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. What security mechanisms does MongoDB provide for data protection?**\n",
        "\n",
        "Ans:\n",
        "MongoDB provides several security mechanisms for data protection, including:\n",
        "Authentication: MongoDB supports various authentication mechanisms, such as username/password, LDAP, and Kerberos.\n",
        "Authorization: Role-Based Access Control (RBAC) allows you to define roles and permissions for users and applications.\n",
        "Encryption: MongoDB supports encryption at rest (using WiredTiger storage engine) and in transit (using TLS/SSL).\n",
        "Auditing: MongoDB provides auditing capabilities to track database events and changes.\n",
        "Network isolation: MongoDB supports network isolation using firewalls, IP whitelisting, and VPC peering.\n",
        "Data encryption: MongoDB supports field-level encryption, allowing you to encrypt specific fields in your documents."
      ],
      "metadata": {
        "id": "2m_LN6P2CNQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.  Explain the concept of embedded documents and when they should be used.**\n",
        "\n",
        "Ans:\n",
        "In MongoDB, embedded documents are documents that are nested inside other documents. They are used to store related data in a single document, reducing the need for separate collections and joins.\n",
        "Embedded documents are useful when:\n",
        "One-to-one relationships: When a document has a single, tightly coupled relationship with another document.\n",
        "One-to-few relationships: When a document has a small number of related documents.\n",
        "Data locality: When related data is frequently accessed together.\n",
        "Benefits of embedded documents:\n",
        "Improved performance: Reduced need for joins and separate queries.\n",
        "Simplified data model: Related data is stored in a single document.\n",
        "Easier data retrieval: Related data can be retrieved in a single query.\n",
        "When to use embedded documents:\n",
        "Frequently accessed together: When related data is often accessed together.\n",
        "Small amounts of data: When the embedded data is relatively small.\n",
        "No need for separate queries: When you don't need to query the embedded data separately."
      ],
      "metadata": {
        "id": "y_b_9YR4CeY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is the purpose of MongoDB’s $lookup stage in aggregation?**\n",
        "\n",
        "Ans:\n",
        "The $lookup stage in MongoDB's aggregation framework is used to:\n",
        "Perform left outer join: Combine data from two collections based on a common field.\n",
        "Enrich documents: Add fields from another collection to the current documents.\n",
        "The $lookup stage allows you to:\n",
        "Join collections: Combine data from multiple collections.\n",
        "Retrieve related data: Fetch data from another collection based on a common field."
      ],
      "metadata": {
        "id": "DmBZYZTdDLEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.  What are some common use cases for MongoDB?**\n",
        "\n",
        "Ans:\n",
        "MongoDB is a versatile database that can be used in a variety of scenarios. Some common use cases include:\n",
        "Real-time analytics: MongoDB's high performance and scalability make it well-suited for real-time analytics and reporting.\n",
        "Content management: MongoDB's flexible schema and document-based data model make it a good fit for content management systems.\n",
        "IoT data storage: MongoDB's ability to handle large amounts of semi-structured data makes it a popular choice for IoT data storage and analysis.\n",
        "Mobile apps: MongoDB's scalability and performance make it a good choice for mobile apps that require a robust backend database.\n",
        "E-commerce platforms: MongoDB's flexibility and scalability make it a popular choice for e-commerce platforms that require a robust product catalog and order management system.\n",
        "Log and event data storage: MongoDB's ability to handle large amounts of semi-structured data makes it a popular choice for log and event data storage and analysis.\n",
        "Personalization and recommendation engines: MongoDB's ability to handle large amounts of data and perform complex queries makes it a good fit for personalization and recommendation engines."
      ],
      "metadata": {
        "id": "hbpkTThqData"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What are the advantages of using MongoDB for horizontal scaling?**\n",
        "\n",
        "Ans:\n",
        "MongoDB provides several advantages for horizontal scaling:\n",
        "Sharding: MongoDB's sharding feature allows you to distribute data across multiple servers, making it easy to scale horizontally.\n",
        "Automatic data distribution: MongoDB automatically distributes data across shards, reducing the complexity of scaling.\n",
        "Load balancing: MongoDB's sharding feature includes load balancing, ensuring that no single server is overwhelmed.\n",
        "Increased storage capacity: By adding more shards, you can increase storage capacity and handle larger amounts of data.\n",
        "Improved performance: Horizontal scaling with MongoDB can improve performance by distributing the load across multiple servers.\n",
        "Easy addition of new nodes: MongoDB makes it easy to add new nodes to a shard, allowing you to scale your database as needed."
      ],
      "metadata": {
        "id": "tApBsYNODpME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. How do MongoDB transactions differ from SQL transactions?**\n",
        "\n",
        "Ans:\n",
        "MongoDB transactions and SQL transactions share some similarities, but they also have some key differences:\n",
        "Multi-document transactions: MongoDB supports multi-document transactions, which allow you to perform atomic operations across multiple documents.\n",
        "Document-level atomicity: In MongoDB, single-document operations are atomic by default, whereas SQL databases typically require explicit transactions for atomicity.\n",
        "Snapshot isolation: MongoDB transactions use snapshot isolation, which ensures that transactions see a consistent view of the data.\n",
        "Distributed transactions: MongoDB supports distributed transactions, which allow you to perform transactions across multiple shards"
      ],
      "metadata": {
        "id": "69hPXjSlEMFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What are the main differences between capped collections and regular collections?**\n",
        "\n",
        "Ans:\n",
        "The main differences between capped collections and regular collections in MongoDB are:\n",
        "Fixed size: Capped collections have a fixed size, whereas regular collections can grow dynamically.\n",
        "FIFO behavior: Capped collections follow a First-In-First-Out (FIFO) behavior, where the oldest documents are automatically removed when the collection reaches its maximum size.\n",
        "Insertion order: Capped collections maintain the insertion order of documents, whereas regular collections do not.\n",
        "High performance: Capped collections are optimized for high-performance logging and queuing applications.\n",
        "Limited updates: Capped collections have limited update capabilities, as documents cannot be resized or updated in a way that would change their size."
      ],
      "metadata": {
        "id": "3_8n665hExEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What is the purpose of the $match stage in MongoDB’s aggregation pipeline?**\n",
        "\n",
        "Ans:\n",
        "The $match stage in MongoDB's aggregation pipeline is used to:\n",
        "Filter documents: Select only the documents that match a specified condition.\n",
        "Reduce data: Reduce the amount of data that needs to be processed in subsequent stages.\n",
        "The $match stage allows you to:\n",
        "Specify conditions: Use query operators to specify conditions for document selection.\n",
        "Use indexes: Take advantage of indexes to improve performance."
      ],
      "metadata": {
        "id": "uVal20q4FT_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. How can you secure access to a MongoDB database?**\n",
        "\n",
        "Ans:\n",
        "To secure access to a MongoDB database:\n",
        "Enable authentication: Require users to authenticate with a username and password.\n",
        "Use role-based access control: Assign roles to users that define their permissions and access levels.\n",
        "Use encryption: Enable encryption at rest and in transit to protect data from unauthorized access.\n",
        "Configure network access: Limit network access to the database using firewalls, IP whitelisting, and VPC peering.\n",
        "Use strong passwords: Enforce strong password policies for all users.\n",
        "Monitor database activity: Use auditing and logging to monitor database activity and detect potential security threats."
      ],
      "metadata": {
        "id": "0JiMzIJ1H5nU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. What is MongoDB’s WiredTiger storage engine, and why is it important?**\n",
        "\n",
        "Ans:\n",
        "WiredTiger is a storage engine in MongoDB that provides:\n",
        "High performance: WiredTiger is designed for high-performance and concurrency.\n",
        "Document-level concurrency: WiredTiger allows for document-level concurrency, reducing contention and improving performance.\n",
        "Compression: WiredTiger provides compression, reducing storage costs and improving data transfer times.\n",
        "Encryption: WiredTiger supports encryption at rest, providing an additional layer of security.\n",
        "Checkpointing: WiredTiger uses checkpointing to ensure data consistency and durability.\n",
        "WiredTiger is important because it:\n",
        "Improves performance: WiredTiger's concurrency and compression features improve overall database performance.\n",
        "Enhances security: WiredTiger's encryption feature provides an additional layer of security for sensitive data.\n",
        "Reduces storage costs: WiredTiger's compression feature reduces storage costs and improves data transfer times."
      ],
      "metadata": {
        "id": "0PmKTu12IGVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***PRACTICAL QUESTIONS***"
      ],
      "metadata": {
        "id": "58k-dHF4AWD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. Write a Python script to load the Superstore dataset from a CSV file into MongoDB?**"
      ],
      "metadata": {
        "id": "5w4QZLBSAf90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTi3vXqMGB5I",
        "outputId": "7e4c0fc6-9a08-4463-8a11-1a81bc84365e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW910l1RANYj",
        "outputId": "e10837b2-98ab-4480-fc40-69d9d00461ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "\n",
        "df= pd.read_csv('superstore.csv', encoding= 'windows-1252')\n",
        "\n",
        "# connect to MongoDB\n",
        "client= MongoClient(\"mongodb+srv://abhinavsk5899:3nrstpbOWZ9U6qfZ@cluster0.45hnw79.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "\n",
        "db= client['RetailStore'] # creating database\n",
        "collection= db['Superstore'] # creating collection\n",
        "\n",
        "# convert datafram to dictionary formate\n",
        "data_dict= df.to_dict(orient='records')\n",
        "\n",
        "# insert into mongodb\n",
        "collection.insert_many(data_dict)\n",
        "\n",
        "# extractig a particular object/document for just checking\n",
        "from bson import ObjectId\n",
        "print(collection.find_one({'_id':ObjectId('688266d8bdafbb3e5b9c0ba8')}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. Retrieve and print all documents from the Orders collection.**"
      ],
      "metadata": {
        "id": "RI96cif4cEW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result= collection.find()\n",
        "\n",
        "#for documents in  result:\n",
        "  #print(documents)\n"
      ],
      "metadata": {
        "id": "VrXSpM0BcM-9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Count and display the total number of documents in the Orders collection.**"
      ],
      "metadata": {
        "id": "uB2nhc4-htnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count= collection.count_documents({})\n",
        "print(f\"Total number of documents in 'Superstore' collection are : {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJKPgyfRhlZh",
        "outputId": "99a39081-d6bf-4e2f-e2e6-1be3900d2125"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of documents in 'Superstore' collection are : 40568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Write a query to fetch all orders from the \"West\" region.**"
      ],
      "metadata": {
        "id": "ExGXVcd9jqXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "region_west= collection.find({'Region':'West'})\n",
        "#for documents in region_west:\n",
        " #pprint.pprint(documents)"
      ],
      "metadata": {
        "id": "Rif_VL2HkEV1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Write a query to find orders where Sales is greater than 500.**"
      ],
      "metadata": {
        "id": "tasVQENbelxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales= collection.find({'Sales':{'$gt':500}})\n",
        "#for documents in sales:\n",
        " # pprint.pprint(documents)"
      ],
      "metadata": {
        "id": "BsVEbMaQeuDa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking how many documents following the above conditions\n",
        "total_documents= collection.count_documents({'Sales':{'$gt':500}})\n",
        "total_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPEMyCWxhTVa",
        "outputId": "8d78cc62-b965-41cd-9f2c-41ef0250a2f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6972"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Fetch the top 3 orders with the highest Profit.**"
      ],
      "metadata": {
        "id": "UEIFIAELlJKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result= collection.find().sort('Profit',-1).limit(3)\n",
        "for documents in result:\n",
        "  pprint.pprint(documents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hcGVsZz7SrS",
        "outputId": "866a25a1-5f71-4ccf-e4e0-34237b77397e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Category': 'Technology',\n",
            " 'City': 'Lafayette',\n",
            " 'Country': 'United States',\n",
            " 'Customer ID': 'TC-20980',\n",
            " 'Customer Name': 'Tamara Chand',\n",
            " 'Discount': 0.0,\n",
            " 'Order Date': '10/2/2016',\n",
            " 'Order ID': 'CA-2016-118689',\n",
            " 'Postal Code': 47905,\n",
            " 'Product ID': 'TEC-CO-10004722',\n",
            " 'Product Name': 'Canon imageCLASS 2200 Advanced Copier',\n",
            " 'Profit': 8399.976,\n",
            " 'Quantity': 5,\n",
            " 'Region': 'Central',\n",
            " 'Row ID': 6827,\n",
            " 'Sales': 17499.95,\n",
            " 'Segment': 'Corporate',\n",
            " 'Ship Date': '10/9/2016',\n",
            " 'Ship Mode': 'Standard Class',\n",
            " 'State': 'Indiana',\n",
            " 'Sub-Category': 'Copiers',\n",
            " '_id': ObjectId('68834f0da79e53d565b8dcd8')}\n",
            "{'Category': 'Technology',\n",
            " 'City': 'Lafayette',\n",
            " 'Country': 'United States',\n",
            " 'Customer ID': 'TC-20980',\n",
            " 'Customer Name': 'Tamara Chand',\n",
            " 'Discount': 0.0,\n",
            " 'Order Date': '10/2/2016',\n",
            " 'Order ID': 'CA-2016-118689',\n",
            " 'Postal Code': 47905,\n",
            " 'Product ID': 'TEC-CO-10004722',\n",
            " 'Product Name': 'Canon imageCLASS 2200 Advanced Copier',\n",
            " 'Profit': 8399.976,\n",
            " 'Quantity': 5,\n",
            " 'Region': 'Central',\n",
            " 'Row ID': 6827,\n",
            " 'Sales': 17499.95,\n",
            " 'Segment': 'Corporate',\n",
            " 'Ship Date': '10/9/2016',\n",
            " 'Ship Mode': 'Standard Class',\n",
            " 'State': 'Indiana',\n",
            " 'Sub-Category': 'Copiers',\n",
            " '_id': ObjectId('68826a44bdafbb3e5b9c2d4d')}\n",
            "{'Category': 'Technology',\n",
            " 'City': 'Lafayette',\n",
            " 'Country': 'United States',\n",
            " 'Customer ID': 'TC-20980',\n",
            " 'Customer Name': 'Tamara Chand',\n",
            " 'Discount': 0.0,\n",
            " 'Order Date': '10/2/2016',\n",
            " 'Order ID': 'CA-2016-118689',\n",
            " 'Postal Code': 47905,\n",
            " 'Product ID': 'TEC-CO-10004722',\n",
            " 'Product Name': 'Canon imageCLASS 2200 Advanced Copier',\n",
            " 'Profit': 8399.976,\n",
            " 'Quantity': 5,\n",
            " 'Region': 'Central',\n",
            " 'Row ID': 6827,\n",
            " 'Sales': 17499.95,\n",
            " 'Segment': 'Corporate',\n",
            " 'Ship Date': '10/9/2016',\n",
            " 'Ship Mode': 'Standard Class',\n",
            " 'State': 'Indiana',\n",
            " 'Sub-Category': 'Copiers',\n",
            " '_id': ObjectId('688266d8bdafbb3e5b9c0643')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Update all orders with Ship Mode as \"First Class\" to \"Premium Class.**"
      ],
      "metadata": {
        "id": "VjHm5p1n9hcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update= collection.update_many({'Ship Mode':'First Class'},\n",
        "                               {'$set':{'Ship Mode':'First Class'}}\n",
        "                               )\n",
        "print(f'Number of total value updated are: {update.matched_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t_46dJK9pEh",
        "outputId": "84ac2ffc-c2d7-4ffd-aaf5-a6b3448b58ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of total value updated are: 6272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Delete all orders where Sales is less than 50.**"
      ],
      "metadata": {
        "id": "f_fWa4oOCk4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete= collection.delete_many({'Sales':{'$lt':50}})\n",
        "print(f'Total deleted documents are {delete.deleted_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ulD0t2EYPa",
        "outputId": "9aaa7007-1370-46df-97df-d598363c9faa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total deleted documents are 9698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Use aggregation to group orders by Region and calculate total sales per region.**"
      ],
      "metadata": {
        "id": "uv-FuqaJF7n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregation pipeline\n",
        "pipeline=[\n",
        "    {\n",
        "        '$group':{\n",
        "            '_id':'$Region',\n",
        "            'total_sales_per_region':{'$sum':'$Sales'}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        '$sort':{'total_sales_per_region':1} # sorting in ascending order\n",
        "    }\n",
        "\n",
        "]\n",
        "\n",
        "# run the aggregation\n",
        "results= collection.aggregate(pipeline)\n",
        "\n",
        "# display the result\n",
        "for region in results:\n",
        "    print(f\"Region: {region['_id']}, Total Sales: {region['total_sales_per_region']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLlg2VjMUhLZ",
        "outputId": "ed0665a7-64d3-4de0-cdf8-07e634ecfee2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Region: South, Total Sales: 2256139.87\n",
            "Region: Central, Total Sales: 2877671.07\n",
            "Region: East, Total Sales: 3906826.23\n",
            "Region: West, Total Sales: 4168119.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Fetch all distinct values for Ship Mode from the collection.**"
      ],
      "metadata": {
        "id": "wXpgr4hNYjez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_ship_mode= collection.distinct('Ship Mode')\n",
        "print(distinct_ship_mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iipMO8ZYYoye",
        "outputId": "444ba515-a2a6-4a5b-8c69-94d42407f335"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['First Class', 'Same Day', 'Second Class', 'Standard Class']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Count the number of orders for each category.**"
      ],
      "metadata": {
        "id": "CtrVwcLXZu_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=[\n",
        "        {'$group':{'_id':'$Category','order_count':{'$sum':1}}},\n",
        "        {'$sort':{'ordercount':-1}}\n",
        "]\n",
        "\n",
        "# run the aggregation\n",
        "result= collection.aggregate(pipeline)\n",
        "\n",
        "# display the result\n",
        "for docs in result:\n",
        "  print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2DSKvSvZz4B",
        "outputId": "3b85882f-5f7e-4011-9243-42c7ff566168"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': 'Technology', 'order_count': 8976}\n",
            "{'_id': 'Furniture', 'order_count': 9438}\n",
            "{'_id': 'Office Supplies', 'order_count': 12456}\n"
          ]
        }
      ]
    }
  ]
}